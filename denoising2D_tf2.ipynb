{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "denoising2D_tf2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEkGAJ8akiSHC1Krcr/RwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yskuchi/wf_denoising/blob/master/denoising2D_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktKu9m1u5WtO"
      },
      "source": [
        "# Waveform denoising 'denoising2D_tf2'\n",
        "Author: Yusuke Uchiyama\n",
        "\n",
        "A denoising convolutional autoencoder with Tensorflow2.x\n",
        "applied to **a set of** waveform data.  \n",
        "See [Bitbucket repository](https://bitbucket.org/meg_ilc_tokyo/wf_denoising/src/master/) or \n",
        "[GitHub repository](https://github.com/yskuchi/wf_denoising)\n",
        "\n",
        "Noise from data is added to MC signal data.\n",
        "You need datasets of signal and noise, separately, in pickle format.\n",
        "\n",
        "## Environment\n",
        "As of 2021 Feb, tested with the following:\n",
        "\n",
        "* Google Colab\n",
        "* CPU, GPU, or TPU (experimental)\n",
        "* Python 3.7\n",
        "* TensorFlow 2.4.1\n",
        "* Comet ML\n",
        "\n",
        "\n",
        "Note: If you are running this in a colab notebook, we recommend you enable a free GPU by going:\n",
        "> Runtime   →   Change runtime type   →   Hardware Accelerator: GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0Fq4Mk53Uz"
      },
      "source": [
        "## Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlAF_nP-58qi"
      },
      "source": [
        "### Comet ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA68Tj_B4pIf"
      },
      "source": [
        "! pip install typing-extensions==3.7.4 comet-ml\n",
        "! pip install typing-extensions==3.7.4\n",
        "#! [ ! -z \"$COLAB_GPU\" ] && pip install typing-extensions==3.7.4 comet-ml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHB2psDB88Nb"
      },
      "source": [
        "# import comet_ml in the top of your file\n",
        "from comet_ml import Experiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88WRgbDT6DHb"
      },
      "source": [
        "### Other packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY8VDwiq5xlT"
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Concatenate\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "print ('Python version: ' + str(sys.version_info))\n",
        "print ('TensorFlow version: ' + str(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXBecYwk9sE"
      },
      "source": [
        "### GPU\n",
        "To use GPU on Google colab, specify GPU in runtime type. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3HXKdnVjbYD"
      },
      "source": [
        "# check GPU\n",
        "tf.test.gpu_device_name()\n",
        "!echo $COLAB_GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo4b4UfblDU2"
      },
      "source": [
        "### TPU\n",
        "To use TPU on Google colab, it is not enough to specify TPU in runtime type.\n",
        "See \"Setup TPU\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooBISQSClYZG"
      },
      "source": [
        "# check TPU\n",
        "!echo $COLAB_TPU_ADDR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR8khwIbBVZK"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGwPpA4BgWi"
      },
      "source": [
        "# arg\n",
        "load_weights = False\n",
        "plot_data = True \n",
        "\n",
        "import matplotlib\n",
        "if not plot_data:\n",
        "    matplotlib.use(\"Agg\") # this is necessary when using plt without display (batch)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Y1ACnmB5PH"
      },
      "source": [
        "# infer signal or noise?\n",
        "extract_signal = True\n",
        "\n",
        "# Number of channels (if 2, two-end signals are dealt with channel)\n",
        "nchannels = 1\n",
        "\n",
        "# Number of waveforms packed in an input data (= Hight of 2D data)\n",
        "height = 16\n",
        "\n",
        "if extract_signal:\n",
        "  filename = f\"denoising2D{height}_tf2\"\n",
        "else:\n",
        "  filename = f'noiseextraction2D{height}ch_tf2'\n",
        "\n",
        "# Waveform has 1024 sample-points\n",
        "npoints = 1024 # 256 # number of sample-points to be used (= Width of 2D data)\n",
        "scale = 1 #5\n",
        "offset = 0 #0.05 # 50 mV\n",
        "\n",
        "signal_dataset_file = 'wf11600.pkl'\n",
        "#noise_dataset_file  = 'wf328469.pkl' #2018\n",
        "noise_dataset_file  = 'wf356990.pkl.bz2' #2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0zbN01DB-Tt"
      },
      "source": [
        "#### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic5qtU4HCCWY"
      },
      "source": [
        "#nkernels = [64, 32, 32,   32, 32, 64] # default for nchannels = 1\n",
        "nkernels = [64, 64, 64,   64, 64, 64]\n",
        "nkernels = [256, 128, 64,   64, 128, 256]\n",
        "#kernel_size = [5, 5, 5]\n",
        "kernel_size = [3, 3, 3]\n",
        "\n",
        "# basic hyper-parameters\n",
        "params = {\n",
        "    'optimizer':   'adam',\n",
        "    'loss':        'mae', #'mse', #'binary_crossentropy', \n",
        "    'metrics':     ['mae', 'mse'],\n",
        "    'epochs':      50, # 20,\n",
        "    'batch_size':  512, #256,\n",
        "}\n",
        "# additional parameters\n",
        "params2 = {\n",
        "    'loss_type':           params['loss'],\n",
        "    'conv_activation':     'relu',\n",
        "    'output_activation':   'linear', #'sigmoid',\n",
        "    'signal_dataset_file': signal_dataset_file,\n",
        "    'noise_dataset_file':  noise_dataset_file,\n",
        "    'npoints':             npoints,\n",
        "    'batch_size':          params['batch_size'],\n",
        "    'scale':               scale,\n",
        "    'offset':              offset,\n",
        "    'nkernels':            nkernels,\n",
        "    'skip_connection':     [True, True, True], # skip connections for UNet-like structure\n",
        "    'nsublayers':          2,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krnakVkaFChi"
      },
      "source": [
        "## Prepare datasets\n",
        "On Google Colb, data is loaded via Google Drive.\n",
        "Files are supposed to be in `/content/drive/My Drive/ML/data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcH3OZVHFa4M"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxb-B8-_FSfK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/My Drive/ML/data/'\n",
        "output_dir = '/content/drive/My Drive/ML/results/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUqm1p9IImg_"
      },
      "source": [
        "### Load pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FgrjGTQIIbA"
      },
      "source": [
        "x_signal = pd.read_pickle(data_dir+signal_dataset_file).to_numpy()\n",
        "x_noise = pd.read_pickle(data_dir+noise_dataset_file ).to_numpy()\n",
        "\n",
        "nsamples = min(len(x_signal), len(x_noise)) \n",
        "nsamples = int(nsamples / (nchannels * height)) * nchannels * height\n",
        "\n",
        "print(f'signal samples:{len(x_signal)}, noise samples:{len(x_noise)}, nsamples: {nsamples}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "derkAEziHewF"
      },
      "source": [
        "if extract_signal:\r\n",
        "  print('Extract signal')\r\n",
        "  x_tobe_removed = x_noise[0:nsamples]\r\n",
        "  x_tobe_extracted = x_signal[0:nsamples]\r\n",
        "else:\r\n",
        "  print('Extract noise')\r\n",
        "  x_tobe_removed = x_signal[0:nsamples]\r\n",
        "  x_tobe_extracted = x_noise[0:nsamples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1hGjvK5JgIn"
      },
      "source": [
        "### Shape data in appropriate format with adding noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFOl1111JivR"
      },
      "source": [
        "x_tobe_removed = x_tobe_removed.astype('float32')\n",
        "x_tobe_removed = x_tobe_removed.T[-npoints:].T # keep last npoints\n",
        "x_tobe_extracted = x_tobe_extracted.astype('float32')\n",
        "x_tobe_extracted = x_tobe_extracted.T[-npoints:].T # keep last npoints\n",
        "\n",
        "# Add noise\n",
        "x_train_noisy = x_tobe_removed + x_tobe_extracted\n",
        "\n",
        "# Adjust scale and offset of waveforms\n",
        "x_tobe_removed *= scale\n",
        "x_tobe_removed += offset * scale\n",
        "x_tobe_extracted *= scale # scale\n",
        "x_tobe_extracted += offset * scale;\n",
        "x_train_noisy *= scale # scale\n",
        "x_train_noisy += offset * scale; # add offset\n",
        "\n",
        "## Values in [0,1]\n",
        "#x_tobe_extracted = np.clip(x_tobe_extracted, 0, 1);\n",
        "#x_train_noisy = np.clip(x_train_noisy, 0, 1);\n",
        "\n",
        "# To match the input shape for Conv2D with n channels\n",
        "ninputs = int(len(x_tobe_removed) / (nchannels * height))\n",
        "x_tobe_removed = np.reshape(x_tobe_removed, (ninputs, height, nchannels, npoints)).transpose(0,1,3,2)\n",
        "x_tobe_extracted = np.reshape(x_tobe_extracted, (ninputs, height, nchannels, npoints)).transpose(0,1,3,2)\n",
        "x_train_noisy = np.reshape(x_train_noisy, (ninputs, height, nchannels, npoints)).transpose(0,1,3,2)\n",
        "\n",
        "print(x_tobe_removed.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0IXI_u4CKCN"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgTOvIWiGeJR"
      },
      "source": [
        "# Add the following code anywhere in your machine learning file\r\n",
        "# api_key and workspace are supposed to be set in .comet.config file,\r\n",
        "# otherwise set here like Experiment(api_key=\"AAAXXX\", workspace = \"yyy\", project_name=\"zzz\")\r\n",
        "# experiment = Experiment(project_name=\"wf_denoising\")\r\n",
        "experiment = Experiment(api_key=\"gBJn86Y1oAYKM2oxaoY0oV4Af\", workspace=\"yskuchi\", project_name=\"wf_denoising\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf7QQHDhTykM"
      },
      "source": [
        "experiment.log_parameters(params2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwS8TkGUlopw"
      },
      "source": [
        "### Setup TPU\n",
        "This part seems tf version dependent and may be changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZK47WZDls95"
      },
      "source": [
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "  tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "  tf.config.experimental_connect_to_cluster(tpu_cluster_resolver) # TF2.0の場合、ここを追加\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver) # TF2.0の場合、今後experimentialが取れる可能性がある    \n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)  # ここも同様\n",
        "  #model = tf.distribute.tpu.keras_to_tpu_model(model, strategy=strategy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iLEhDoLzeYQ"
      },
      "source": [
        "### Build model with functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yusCHYE3CNTD"
      },
      "source": [
        "def build_model():\n",
        "  input_img = Input(shape=(height, npoints,nchannels))\n",
        "  conv1 = Conv2D(params2['nkernels'][0], (1, kernel_size[0]), padding='same', activation=params2['conv_activation'])(input_img)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv1 = Conv2D(params2['nkernels'][0], (1, kernel_size[0]), padding='same', activation=params2['conv_activation'])(conv1)\n",
        "  pool1 = MaxPooling2D((1,2), padding='same')(conv1)\n",
        "  conv2 = Conv2D(params2['nkernels'][1], (1, kernel_size[1]), padding='same', activation=params2['conv_activation'])(pool1)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv2 = Conv2D(params2['nkernels'][1], (1, kernel_size[1]), padding='same', activation=params2['conv_activation'])(conv2)\n",
        "  pool2 = MaxPooling2D((1,2), padding='same')(conv2)\n",
        "  conv3 = Conv2D(params2['nkernels'][2], (1, kernel_size[2]), padding='same', activation=params2['conv_activation'])(pool2)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv3 = Conv2D(params2['nkernels'][2], (1, kernel_size[2]), padding='same', activation=params2['conv_activation'])(conv32)\n",
        "  encoded = MaxPooling2D((1,2), padding='same')(conv3)\n",
        "\n",
        "  conv4 = Conv2D(params2['nkernels'][3], (1, kernel_size[2]), padding='same', activation=params2['conv_activation'])(encoded)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv4 = Conv2D(params2['nkernels'][3], (1, kernel_size[2]), padding='same', activation=params2['conv_activation'])(conv4)\n",
        "  up5 = UpSampling2D((1,2))(conv4)\n",
        "  if params2['skip_connection'][2]:\n",
        "    up5 = Concatenate()([up5, conv3])\n",
        "  conv5 = Conv2D(params2['nkernels'][4], (1, kernel_size[1]), padding='same', activation=params2['conv_activation'])(up5)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv5 = Conv2D(params2['nkernels'][4], (1, kernel_size[1]), padding='same', activation=params2['conv_activation'])(conv5)\n",
        "  up6 = UpSampling2D((1,2))(conv5)\n",
        "  if params2['skip_connection'][1]:\n",
        "    up6 = Concatenate()([up6, conv2])\n",
        "  conv6 = Conv2D(params2['nkernels'][5], (1, kernel_size[0]), padding='same', activation=params2['conv_activation'])(up6)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv6 = Conv2D(params2['nkernels'][5], (1, kernel_size[0]), padding='same', activation=params2['conv_activation'])(conv6)\n",
        "  up7 = UpSampling2D((1,2))(conv6)\n",
        "  if params2['skip_connection'][0]:\n",
        "    up7 = Concatenate()([up7, conv1])\n",
        "  decoded = Conv2D(nchannels, (1, 3), padding='same', activation=params2['output_activation'])(up7)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    decoded = Conv2D(nchannels, (1, 3), padding='same', activation=params2['output_activation'])(decode)\n",
        "\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded)\n",
        "\n",
        "  autoencoder.compile(optimizer=params['optimizer'], loss=params['loss'], metrics=params['metrics']) \n",
        "  autoencoder.summary()\n",
        "  return autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldVS0BzqR9C9"
      },
      "source": [
        "try:\n",
        "  strategy\n",
        "  with strategy.scope():\n",
        "    autoencoder = build_model()\n",
        "except NameError:\n",
        "  autoencoder = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvNS_i04KgZC"
      },
      "source": [
        "## Fit\n",
        "\n",
        "On Google Colb, the results (trained model) are saved in Google Drive. Files are supposed to be in /content/drive/My Drive/ML/results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-o1mGrzJR6a"
      },
      "source": [
        "history=[]\n",
        "if not load_weights:\n",
        "\n",
        "    # Callback for model checkpoints\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath = output_dir + filename + \"-{epoch:02d}.h5\",\n",
        "        save_best_only=True,\n",
        "        save_weight_only=False)\n",
        "    \n",
        "    # 'labels' are the pictures themselves\n",
        "    hist = autoencoder.fit(x_train_noisy, x_tobe_extracted,\n",
        "                           epochs=params['epochs'],\n",
        "                           batch_size=params['batch_size'],\n",
        "                           shuffle=True,\n",
        "                           validation_split=0.1)#,\n",
        "                           #callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "    # Save history\n",
        "    with open(output_dir + filename + '_hist.json', 'w') as f:\n",
        "        json.dump(hist.history, f)\n",
        "    history = hist.history\n",
        "        \n",
        "    # Save the weights\n",
        "    autoencoder.save_weights(output_dir + filename + '_weights.h5')\n",
        "else:\n",
        "    # Load weights\n",
        "    autoencoder.load_weights(f'{output_dir}{filename}_weights.h5')\n",
        "\n",
        "    # Load history\n",
        "    with open(f'{output_dir}{filename}_hist.json', 'r') as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "autoencoder.save(output_dir + filename + '.h5', include_optimizer=False)\n",
        "        \n",
        "# Plot training history \n",
        "#plt.plot(history['loss'], linewidth=3, label='train')\n",
        "#plt.plot(history['val_loss'], linewidth=3, label='valid')\n",
        "plt.plot(history['mae'], linewidth=3, label='train')\n",
        "plt.plot(history['val_mae'], linewidth=3, label='valid')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "if params['metrics'] == 'mse':\n",
        "  plt.ylim(1e-6 * scale, 0.1e-3 * scale) #mse\n",
        "else:\n",
        "  plt.ylim(0.5e-3 * scale, 0.5e-2 * scale) #mae\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur-JWTe4WI0y"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fYGvPDyWLQz"
      },
      "source": [
        "x_test_tobe_removed = x_tobe_removed[0:]\n",
        "x_test_tobe_extracted = x_tobe_extracted[0:]\n",
        "x_test_noisy = x_train_noisy[0:]\n",
        "print(x_test_noisy.shape)\n",
        "\n",
        "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
        "decoded_imgs =decoded_imgs[0:len(x_test_noisy)]\n",
        "\n",
        "print(decoded_imgs.shape)\n",
        "\n",
        "# revert scale and offset\n",
        "x_test_tobe_removed -= scale * offset\n",
        "x_test_tobe_removed /= scale\n",
        "x_test_tobe_extracted -= scale * offset\n",
        "x_test_tobe_extracted /= scale\n",
        "x_test_noisy -= scale * offset\n",
        "x_test_noisy /= scale\n",
        "decoded_imgs -= scale * offset\n",
        "decoded_imgs /= scale\n",
        "x_subtracted = x_test_tobe_extracted - decoded_imgs\n",
        "\n",
        "print(x_test_tobe_extracted.shape)\n",
        "print(x_test_noisy.shape)\n",
        "\n",
        "x_test_tobe_removed = x_test_tobe_removed.transpose(0,1, 3, 2)\n",
        "x_test_tobe_removed = np.reshape(x_test_tobe_removed, (len(x_test_tobe_removed) * height * nchannels, npoints))\n",
        "x_test_tobe_extracted = x_test_tobe_extracted.transpose(0,1, 3, 2)\n",
        "x_test_tobe_extracted = np.reshape(x_test_tobe_extracted, (len(x_test_tobe_extracted) * height * nchannels, npoints))\n",
        "x_test_noisy = x_test_noisy.transpose(0,1,3,2)\n",
        "x_test_noisy = np.reshape(x_test_noisy, (len(x_test_noisy) * height * nchannels, npoints))\n",
        "decoded_imgs = decoded_imgs.transpose(0,1,3,2)\n",
        "decoded_imgs = np.reshape(decoded_imgs, (len(decoded_imgs) * height * nchannels, npoints))\n",
        "x_subtracted = x_subtracted.transpose(0,1,3,2)\n",
        "x_subtracted = np.reshape(x_subtracted, (len(x_subtracted) * height * nchannels, npoints))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYNfJ9rK0ouw"
      },
      "source": [
        "# How many waveforms to be displayed\n",
        "n = 2\n",
        "start = 16                \n",
        "fig = plt.figure(figsize=(20, 6 * n))\n",
        "j = 0\n",
        "for i in range(start, start + n):\n",
        "  ax = fig.add_subplot(n, 1, j+1)\n",
        "  #ax.plot(x_test_tobe_removed[i], label=\"original\")\n",
        "  ax.plot(x_test_noisy[i], label=\"noisy\", color='gray')\n",
        "  if extract_signal:\n",
        "    ax.plot(x_test_tobe_extracted[i], label=\"signal\", color='green')\n",
        "  else:\n",
        "    ax.plot(x_test_tobe_extracted[i], label=\"noise\", color='green')\n",
        "  ax.plot(decoded_imgs[i], label=\"decoded\", color='magenta')\n",
        "  #ax.plot(x_subtracted[i], label=\"subtracted\")\n",
        "  ax.legend()\n",
        "  j += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H42-gn6xUocT"
      },
      "source": [
        "# Send this plot to comet\n",
        "experiment.log_figure(figure=fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jWr9AZJwXH"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXYB7Ai4VYhB"
      },
      "source": [
        "if plot_data:\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}