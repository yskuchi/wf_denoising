{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "noiseextraction2ch_tf2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yskuchi/wf_denoising/blob/master/denoising1D_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktKu9m1u5WtO"
      },
      "source": [
        "# Waveform denoising 'denoising1D_tf2'\n",
        "Author: Yusuke Uchiyama\n",
        "\n",
        "A denoising convolutional autoencoder with Tensorflow2.x\n",
        "applied to **a set of or single** waveform data using 1D convolutional autoencoder with multiple input channels.  \n",
        "See [Bitbucket repository](https://bitbucket.org/meg_ilc_tokyo/wf_denoising/src/master/) or \n",
        "[GitHub repository](https://github.com/yskuchi/wf_denoising)\n",
        "\n",
        "Noise from data is added to MC signal data.\n",
        "You need datasets of signal and noise, separately, in pickle format.\n",
        "\n",
        "## Environment\n",
        "As of 2022 Aug, tested with the following:\n",
        "\n",
        "* Google Colab\n",
        "* CPU, GPU, or TPU (experimental)\n",
        "* Python 3.7\n",
        "* TensorFlow 2.8.2\n",
        "* Comet ML 3.31\n",
        "\n",
        "\n",
        "Note: If you are running this in a colab notebook, we recommend you enable a free GPU by going:\n",
        "> Runtime   →   Change runtime type   →   Hardware Accelerator: GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0Fq4Mk53Uz"
      },
      "source": [
        "## Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlAF_nP-58qi"
      },
      "source": [
        "### Comet ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA68Tj_B4pIf"
      },
      "source": [
        "! pip install typing-extensions comet-ml\n",
        "! pip install typing-extensions\n",
        "#! [ ! -z \"$COLAB_GPU\" ] && pip install typing-extensions==3.7.4 comet-ml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHB2psDB88Nb"
      },
      "source": [
        "# import comet_ml in the top of your file\n",
        "from comet_ml import Experiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88WRgbDT6DHb"
      },
      "source": [
        "### Other packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY8VDwiq5xlT"
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D, Concatenate\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "print ('Python version: ' + str(sys.version_info))\n",
        "print ('TensorFlow version: ' + str(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXBecYwk9sE"
      },
      "source": [
        "### GPU\n",
        "To use GPU on Google colab, specify GPU in runtime type. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3HXKdnVjbYD"
      },
      "source": [
        "# check GPU\n",
        "tf.test.gpu_device_name()\n",
        "!echo $COLAB_GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo4b4UfblDU2"
      },
      "source": [
        "### TPU\n",
        "To use TPU on Google colab, it is not enough to specify TPU in runtime type.\n",
        "See \"Setup TPU\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooBISQSClYZG"
      },
      "source": [
        "# check TPU\n",
        "!echo $COLAB_TPU_ADDR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR8khwIbBVZK"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGwPpA4BgWi"
      },
      "source": [
        "# arg\n",
        "load_weights = False\n",
        "plot_data = True \n",
        "\n",
        "import matplotlib\n",
        "if not plot_data:\n",
        "    matplotlib.use(\"Agg\") # this is necessary when using plt without display (batch)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Y1ACnmB5PH"
      },
      "source": [
        "# infer signal (0), noise (1), or 1st cluster (2)?\n",
        "extract_type = 2\n",
        "\n",
        "\n",
        "# Number of channels (CNN channel = waveform channanels)\n",
        "#nchannels = 1\n",
        "nchannels = 2\n",
        "\n",
        "if extract_type == 0:\n",
        "  filename = f\"denoising1D{nchannels}ch_tf2\"\n",
        "elif extract_type == 1:\n",
        "  filename = f'noiseextraction1D{nchannels}ch_tf2'\n",
        "else:\n",
        "  filename = f'clustertiming1D{nchannels}ch_tf2' \n",
        "\n",
        "# Waveform has 1024 sample-points\n",
        "npoints = 512 # 256 # number of sample-points to be used\n",
        "scale = 1 #5\n",
        "offset = 0.0 #0.05 # 50 mV\n",
        "\n",
        "#signal_dataset_file = 'wf11600.pkl.gz'\n",
        "##noise_dataset_file  = 'wf328469.pkl' #2018\n",
        "#noise_dataset_file  = 'wf356990.pkl.gz' #2020\n",
        "#signal_dataset_file = 'wf_spx13000.pkl.gz'\n",
        "#noise_dataset_file  = 'wf_spx397695.pkl.gz' #2021\n",
        "signal_dataset_file = 'wf_cdch13000.pkl.gz'\n",
        "noise_dataset_file  = 'wf402042.pkl.gz' #2021\n",
        "cluster_dataset_file = 'cls1st_cdch13000.pkl.gz' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0zbN01DB-Tt"
      },
      "source": [
        "#### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic5qtU4HCCWY"
      },
      "source": [
        "kernel_size = [9, 9, 9]\n",
        "\n",
        "# basic hyper-parameters\n",
        "params = {\n",
        "    'optimizer':   'adam',\n",
        "    'loss':        'mse',\n",
        "    'metrics':     ['mae', 'mse'],\n",
        "    'epochs':      150, # 20,\n",
        "    'batch_size':  512, #256,\n",
        "    'steps_per_execution': 100, # default 1, for TPU larger value may help\n",
        "}\n",
        "if extract_type == 0:\n",
        "  params['loss'] = 'msle'\n",
        "elif extract_type == 2:\n",
        "  params['loss'] = 'binary_crossentropy'\n",
        "\n",
        "# additional parameters\n",
        "params2 = {\n",
        "    'loss_type':           params['loss'],\n",
        "    'conv_activation':     'relu',\n",
        "    'output_activation':   'linear', #'sigmoid',\n",
        "    'signal_dataset_file': signal_dataset_file,\n",
        "    'noise_dataset_file':  noise_dataset_file,\n",
        "    'File name':           filename + '.ipynb',\n",
        "    'batch_size':          params['batch_size'],\n",
        "    'npoints':             npoints,\n",
        "    'nchannels':           nchannels,\n",
        "    'nrows':               1,\n",
        "    'scale':               scale,\n",
        "    'offset':              offset,\n",
        "    'nsublayers':          1,\n",
        "    'nkernels':            [128, 64, 64,   64, 64, 128],\n",
        "    'kernel_size':         kernel_size,\n",
        "    'skip_connection':     [True, True, True],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krnakVkaFChi"
      },
      "source": [
        "## Prepare datasets\n",
        "On Google Colb, data is loaded via Google Drive.\n",
        "Files are supposed to be in `/content/drive/My Drive/ML/data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcH3OZVHFa4M"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxb-B8-_FSfK"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#data_dir = '/content/drive/My Drive/ML/data/'\n",
        "#output_dir = '/content/drive/My Drive/ML/results/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Here is a trick to mount Drive in other account\n",
        "## First, run this column and click the URL shown in the error message.\n",
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ],
      "metadata": {
        "id": "J55razGlv0o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "BAPJnnQ0v6cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/ML/data/'\n",
        "output_dir = '/content/drive/MyDrive/ML/results/'"
      ],
      "metadata": {
        "id": "OFFb5Ikm3YHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUqm1p9IImg_"
      },
      "source": [
        "### Load pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FgrjGTQIIbA"
      },
      "source": [
        "x_signal = pd.read_pickle(data_dir+signal_dataset_file).to_numpy()\n",
        "x_noise = pd.read_pickle(data_dir+noise_dataset_file ).to_numpy()\n",
        "if extract_type == 2:\n",
        "  x_cluster = pd.read_pickle(data_dir+cluster_dataset_file ).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6zzRJxSlzxe"
      },
      "source": [
        "nsamples = min(len(x_signal), len(x_noise)) \n",
        "nsamples = int(nsamples / nchannels) * nchannels\n",
        "\n",
        "print(f'signal samples:{len(x_signal)}, noise samples:{len(x_noise)}, nsamples: {nsamples}')\n",
        "\n",
        "if extract_type == 0:\n",
        "  print('Extract signal')\n",
        "  x_tobe_removed = x_noise[0:nsamples]\n",
        "  x_tobe_extracted = x_signal[0:nsamples]\n",
        "  x_true_signal = x_tobe_extracted\n",
        "elif extract_type == 1:\n",
        "  print('Extract noise')\n",
        "  x_tobe_removed = x_signal[0:nsamples]\n",
        "  x_tobe_extracted = x_noise[0:nsamples]\n",
        "  x_true_signal = x_tobe_extracted\n",
        "else:\n",
        "  x_tobe_removed = x_noise[0:nsamples]\n",
        "  x_tobe_extracted = x_cluster[0:nsamples]\n",
        "  x_true_signal = x_signal[0:nsamples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1hGjvK5JgIn"
      },
      "source": [
        "### Shape data in appropriate format with adding noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFOl1111JivR"
      },
      "source": [
        "x_tobe_removed = x_tobe_removed.astype('float32')\n",
        "x_tobe_removed = x_tobe_removed.T[-npoints:].T # keep last npoints\n",
        "x_tobe_extracted = x_tobe_extracted.astype('float32')\n",
        "x_tobe_extracted = x_tobe_extracted.T[-npoints:].T # keep last npoints\n",
        "x_true_signal = x_true_signal.astype('float32')\n",
        "x_true_signal = x_true_signal.T[-npoints:].T # keep last npoints\n",
        "\n",
        "# Add noise\n",
        "x_train_noisy = x_tobe_removed + x_true_signal\n",
        "\n",
        "# Adjust scale and offset of waveforms\n",
        "x_tobe_removed *= scale\n",
        "x_tobe_removed += offset * scale\n",
        "x_tobe_extracted *= scale # scale\n",
        "x_tobe_extracted += offset * scale;\n",
        "x_train_noisy *= scale # scale\n",
        "x_train_noisy += offset * scale; # add offset\n",
        "x_true_signal *= scale\n",
        "\n",
        "## Values in [0,1]\n",
        "#x_tobe_extracted = np.clip(x_tobe_extracted, 0, 1);\n",
        "#x_train_noisy = np.clip(x_train_noisy, 0, 1);\n",
        "\n",
        "# To match the input shape for Conv1D with n channels\n",
        "x_tobe_removed = np.reshape(x_tobe_removed, (int(len(x_tobe_removed) / nchannels), nchannels, npoints)).transpose(0,2,1)\n",
        "x_tobe_extracted = np.reshape(x_tobe_extracted, (int(len(x_tobe_extracted) / nchannels), nchannels, npoints)).transpose(0,2,1)\n",
        "x_train_noisy = np.reshape(x_train_noisy, (int(len(x_train_noisy) / nchannels), nchannels, npoints)).transpose(0,2,1)\n",
        "x_true_signal = np.reshape(x_true_signal, (int(len(x_true_signal) / nchannels), nchannels, npoints)).transpose(0,2,1)\n",
        "\n",
        "print(x_tobe_removed.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0IXI_u4CKCN"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jybA-nKzj8Xw"
      },
      "source": [
        "# Add the following code anywhere in your machine learning file\n",
        "# api_key and workspace are supposed to be set in .comet.config file,\n",
        "# otherwise set here like Experiment(api_key=\"AAAXXX\", workspace = \"yyy\", project_name=\"zzz\")\n",
        "# experiment = Experiment(project_name=\"wf_denoising\")\n",
        "experiment = Experiment(api_key=\"gBJn86Y1oAYKM2oxaoY0oV4Af\", workspace=\"yskuchi\", project_name=\"wf_denoising\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf7QQHDhTykM"
      },
      "source": [
        "experiment.log_parameters(params2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwS8TkGUlopw"
      },
      "source": [
        "### Setup TPU\n",
        "This part seems tf version dependent and may be changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZK47WZDls95"
      },
      "source": [
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "  tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "  tf.config.experimental_connect_to_cluster(tpu_cluster_resolver) # TF2.0の場合、ここを追加\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver) # TF2.0の場合、今後experimentialが取れる可能性がある    \n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)  # ここも同様\n",
        "  #model = tf.distribute.tpu.keras_to_tpu_model(model, strategy=strategy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iLEhDoLzeYQ"
      },
      "source": [
        "### Build model with functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yusCHYE3CNTD"
      },
      "source": [
        "def build_model():\n",
        "  input_img = Input(shape=(npoints,nchannels))\n",
        "  conv1 = Conv1D(params2['nkernels'][0], kernel_size[0], padding='same', activation=params2['conv_activation'])(input_img)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv1 = Conv1D(params2['nkernels'][0], kernel_size[0], padding='same', activation=params2['conv_activation'])(conv1)\n",
        "  pool1 = MaxPooling1D(2, padding='same')(conv1)\n",
        "  conv2 = Conv1D(params2['nkernels'][1], kernel_size[1], padding='same', activation=params2['conv_activation'])(pool1)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv2 = Conv1D(params2['nkernels'][1], kernel_size[1], padding='same', activation=params2['conv_activation'])(conv2)\n",
        "  pool2 = MaxPooling1D(2, padding='same')(conv2)\n",
        "  conv3 = Conv1D(params2['nkernels'][2], kernel_size[2], padding='same', activation=params2['conv_activation'])(pool2)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv3 = Conv1D(params2['nkernels'][2], kernel_size[2], padding='same', activation=params2['conv_activation'])(conv3)\n",
        "  encoded = MaxPooling1D(2, padding='same')(conv3)\n",
        "\n",
        "  conv4 = Conv1D(params2['nkernels'][3], kernel_size[2], padding='same', activation=params2['conv_activation'])(encoded)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv4 = Conv1D(params2['nkernels'][3], kernel_size[2], padding='same', activation=params2['conv_activation'])(conv4)\n",
        "  up5 = UpSampling1D(2)(conv4)\n",
        "  if params2['skip_connection'][2]:\n",
        "    up5 = Concatenate()([up5, conv3])\n",
        "  conv5 = Conv1D(params2['nkernels'][4], kernel_size[1], padding='same', activation=params2['conv_activation'])(up5)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv5 = Conv1D(params2['nkernels'][4], kernel_size[1], padding='same', activation=params2['conv_activation'])(conv5)\n",
        "  up6 = UpSampling1D(2)(conv5)\n",
        "  if params2['skip_connection'][1]:\n",
        "    up6 = Concatenate()([up6, conv2])\n",
        "  conv6 = Conv1D(params2['nkernels'][5], kernel_size[0], padding='same', activation=params2['conv_activation'])(up6)\n",
        "  for i in range(1, params2['nsublayers']):\n",
        "    conv6 = Conv1D(params2['nkernels'][5], kernel_size[0], padding='same', activation=params2['conv_activation'])(conv6)\n",
        "  up7 = UpSampling1D(2)(conv6)\n",
        "  if params2['skip_connection'][0]:\n",
        "    up7 = Concatenate()([up7, conv1])\n",
        "  for i in range(params2['nsublayers'] - 1):\n",
        "    up7 = Conv1D(1, kernel_size[0], padding='same', activation=params2['conv_activation'])(up7)\n",
        "  decoded = Conv1D(nchannels, kernel_size[0], padding='same', activation=params2['output_activation'])(up7)\n",
        "\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded)\n",
        "\n",
        "  autoencoder.compile(optimizer=params['optimizer'], \n",
        "                      loss=params['loss'], \n",
        "                      metrics=params['metrics'],\n",
        "                      steps_per_execution=params['steps_per_execution']) \n",
        "  autoencoder.summary()\n",
        "  return autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldVS0BzqR9C9"
      },
      "source": [
        "try:\n",
        "  strategy\n",
        "  with strategy.scope():\n",
        "    autoencoder = build_model()\n",
        "except NameError:\n",
        "  autoencoder = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvNS_i04KgZC"
      },
      "source": [
        "## Fit\n",
        "\n",
        "On Google Colb, the results (trained model) are saved in Google Drive. Files are supposed to be in /content/drive/My Drive/ML/results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-o1mGrzJR6a"
      },
      "source": [
        "history=[]\n",
        "if not load_weights:\n",
        "\n",
        "    # Callback for model checkpoints\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath = output_dir + filename + \"-{epoch:02d}.h5\",\n",
        "        save_best_only=True,\n",
        "        save_weight_only=False)\n",
        "    \n",
        "    # 'labels' are the pictures themselves\n",
        "    hist = autoencoder.fit(x_train_noisy, x_tobe_extracted,\n",
        "                           epochs=params['epochs'],\n",
        "                           batch_size=params['batch_size'],\n",
        "                           shuffle=True,\n",
        "                           validation_split=0.1)#,\n",
        "                           #callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "    # Save history\n",
        "    with open(output_dir + filename + '_hist.json', 'w') as f:\n",
        "        json.dump(hist.history, f)\n",
        "    history = hist.history\n",
        "        \n",
        "    # Save the weights\n",
        "    autoencoder.save_weights(output_dir + filename + '_weights.h5')\n",
        "else:\n",
        "    # Load weights\n",
        "    autoencoder.load_weights(f'{output_dir}{filename}_weights.h5')\n",
        "\n",
        "    # Load history\n",
        "    with open(f'{output_dir}{filename}_hist.json', 'r') as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "autoencoder.save(output_dir + filename + '.h5', include_optimizer=False)\n",
        "        \n",
        "# Plot training history \n",
        "#plt.plot(history['loss'], linewidth=3, label='train')\n",
        "#plt.plot(history['val_loss'], linewidth=3, label='valid')\n",
        "plt.plot(history['mae'], linewidth=3, label='train')\n",
        "plt.plot(history['val_mae'], linewidth=3, label='valid')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "if params['metrics'] == 'mse':\n",
        "  plt.ylim(1e-6 * scale, 0.1e-3 * scale) #mse\n",
        "else:\n",
        "  plt.ylim(0.5e-3 * scale, 0.5e-2 * scale) #mae\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur-JWTe4WI0y"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fYGvPDyWLQz"
      },
      "source": [
        "x_test_tobe_removed = x_tobe_removed[0:]\n",
        "x_test_tobe_extracted = x_tobe_extracted[0:]\n",
        "x_test_noisy = x_train_noisy[0:]\n",
        "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
        "\n",
        "# revert scale and offset\n",
        "x_test_tobe_removed -= scale * offset\n",
        "x_test_tobe_removed /= scale\n",
        "x_test_tobe_extracted -= scale * offset\n",
        "x_test_tobe_extracted /= scale\n",
        "x_test_noisy -= scale * offset\n",
        "x_test_noisy /= scale\n",
        "decoded_imgs -= scale * offset\n",
        "decoded_imgs /= scale\n",
        "#x_subtracted = x_test_tobe_extracted - decoded_imgs\n",
        "\n",
        "print(x_test_tobe_extracted.shape)\n",
        "print(x_test_noisy.shape)\n",
        "\n",
        "x_test_tobe_removed = x_test_tobe_removed.transpose(0,2,1)\n",
        "x_test_tobe_removed = np.reshape(x_test_tobe_removed, (len(x_test_tobe_removed) * nchannels, npoints))\n",
        "x_test_tobe_extracted = x_test_tobe_extracted.transpose(0,2,1)\n",
        "x_test_tobe_extracted = np.reshape(x_test_tobe_extracted, (len(x_test_tobe_extracted) * nchannels, npoints))\n",
        "x_test_noisy = x_test_noisy.transpose(0,2,1)\n",
        "x_test_noisy = np.reshape(x_test_noisy, (len(x_test_noisy) * nchannels, npoints))\n",
        "decoded_imgs = decoded_imgs.transpose(0,2,1)\n",
        "decoded_imgs = np.reshape(decoded_imgs, (len(decoded_imgs) * nchannels, npoints))\n",
        "\n",
        "#x_subtracted = x_subtracted.transpose(0,2,1)\n",
        "#x_subtracted = np.reshape(x_subtracted, (len(x_subtracted) * nchannels, npoints))\n",
        "x_residual = x_test_tobe_extracted - decoded_imgs\n",
        "x_decoded_signal = decoded_imgs\n",
        "if extract_type == 1:\n",
        "  x_decoded_signal = x_test_noisy - decoded_imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYNfJ9rK0ouw"
      },
      "source": [
        "# How many waveforms to be displayed\n",
        "n = 2\n",
        "start = 16\n",
        "fig = plt.figure(figsize=(20, 6 * n))\n",
        "j = 0\n",
        "for i in range(start, start + n):\n",
        "  ax = fig.add_subplot(n, 1, j+1)\n",
        "  #ax.plot(x_test_tobe_removed[i], label=\"original\")\n",
        "  ax.plot(x_test_noisy[i], label=\"noisy\", color='gray')\n",
        "  if extract_type == 1:\n",
        "    ax.plot(x_test_tobe_extracted[i], label=\"noise\", color='green')\n",
        "    ax.plot(x_test_tobe_removed[i], label=\"signal\")\n",
        "    ax.plot(x_decoded_signal[i], label=\"extracted signal\")\n",
        "  else:\n",
        "    ax.plot(x_test_tobe_extracted[i], label=\"signal\", color='green')\n",
        "  ax.plot(decoded_imgs[i], label=\"decoded\", color='magenta')\n",
        "  ax.plot(x_residual[i], label=\"residual\")\n",
        "  ax.legend()\n",
        "  j += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H42-gn6xUocT"
      },
      "source": [
        "# Send this plot to comet\n",
        "experiment.log_figure(figure=fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-jWr9AZJwXH"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXYB7Ai4VYhB"
      },
      "source": [
        "if plot_data:\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}