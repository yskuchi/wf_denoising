{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "denoising5_tf2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPD2pKXBBUQOg+Mt0jyuZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yskuchi/wf_denoising/blob/master/denoising5_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktKu9m1u5WtO",
        "colab_type": "text"
      },
      "source": [
        "# Waveform denoising 'denoising5_tf2'\n",
        "\n",
        "A denoising convolutional autoencoder with Tensorflow2.x\n",
        "applied to waveform data.\n",
        "\n",
        "Noise from data is added to MC signal data.\n",
        "You need datasets of signal and noise, separately, in pickle format.\n",
        "\n",
        "See [Bitbucket repository](https://bitbucket.org/meg_ilc_tokyo/wf_denoising/src/master/) or \n",
        "[GitHub repository](https://github.com/yskuchi/wf_denoising)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0Fq4Mk53Uz",
        "colab_type": "text"
      },
      "source": [
        "## Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlAF_nP-58qi",
        "colab_type": "text"
      },
      "source": [
        "### Comet ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA68Tj_B4pIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install comet-ml\n",
        "#! [ ! -z \"$COLAB_GPU\" ] && pip install comet-ml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB-g6ovr_QeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install typing-extensions==3.7.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHB2psDB88Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import comet_ml in the top of your file\n",
        "from comet_ml import Experiment\n",
        "\n",
        "# Add the following code anywhere in your machine learning file\n",
        "# api_key and workspace are supposed to be set in .comet.config file,\n",
        "# otherwise set here like Experiment(api_key=\"AAAXXX\", workspace = \"yyy\", project_name=\"zzz\")\n",
        "# experiment = Experiment(project_name=\"wf_denoising\")\n",
        "experiment = Experiment(api_key=\"gBJn86Y1oAYKM2oxaoY0oV4Af\", workspace=\"yskuchi\", project_name=\"wf_denoising\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88WRgbDT6DHb",
        "colab_type": "text"
      },
      "source": [
        "### Other packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY8VDwiq5xlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR8khwIbBVZK",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGwPpA4BgWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# arg\n",
        "load_weights = False\n",
        "plot_data = True \n",
        "filename = \"denoising5_tf2\"\n",
        "\n",
        "import matplotlib\n",
        "if not plot_data:\n",
        "    matplotlib.use(\"Agg\") # this is necessary when using plt without display (batch)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Y1ACnmB5PH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Waveform has 1024 sample-points\n",
        "npoints = 1024 # 256 # number of sample-points to be used\n",
        "scale = 5\n",
        "offset = 0.05 # 50 mV\n",
        "\n",
        "signal_dataset_file = 'wf11100.pkl'\n",
        "noise_dataset_file  = 'wf328469.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0zbN01DB-Tt",
        "colab_type": "text"
      },
      "source": [
        "#### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic5qtU4HCCWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic hyper-parameters\n",
        "params = {\n",
        "    'optimizer':   'adam',\n",
        "    'loss':        'mse', #'binary_crossentropy', \n",
        "    'epochs':      10, # 20,\n",
        "    'batch_size':  256,\n",
        "}\n",
        "# additional parameters\n",
        "params2 = {\n",
        "    'conv_activation':     'relu',\n",
        "    'output_activation':   'linear', #'sigmoid',\n",
        "    'signal_dataset_file': signal_dataset_file,\n",
        "    'noise_dataset_file':  noise_dataset_file,\n",
        "    'npoints':             npoints,\n",
        "    'scale':               scale,\n",
        "    'offset':              offset,\n",
        "}\n",
        "experiment.log_parameters(params2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krnakVkaFChi",
        "colab_type": "text"
      },
      "source": [
        "## Prepare datasets\n",
        "On Google Colb, data is loaded via Google Drive.\n",
        "Files are supposed to be in `/content/drive/My Drive/ML/data`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcH3OZVHFa4M",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxb-B8-_FSfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/My Drive/ML/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUqm1p9IImg_",
        "colab_type": "text"
      },
      "source": [
        "### Load pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FgrjGTQIIbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_original = pd.read_pickle(data_dir+signal_dataset_file).to_numpy()\n",
        "x_noise = pd.read_pickle(data_dir+noise_dataset_file ).to_numpy()\n",
        "\n",
        "nsamples = min(len(x_original), len(x_noise))\n",
        "x_original = x_original[0:nsamples]\n",
        "x_noise = x_noise[0:nsamples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1hGjvK5JgIn",
        "colab_type": "text"
      },
      "source": [
        "### Shape data in appropriate format with adding noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFOl1111JivR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_original = x_original.astype('float32')\n",
        "x_original = x_original.T[-npoints:].T # keep last npoints\n",
        "x_noise = x_noise.astype('float32')\n",
        "x_noise = x_noise.T[-npoints:].T # keep last npoints\n",
        "\n",
        "# Add noise\n",
        "x_train_noisy = x_original + x_noise\n",
        "\n",
        "# Adjust scale and offset of waveforms\n",
        "x_original *= scale # scale\n",
        "x_original += offset * scale;\n",
        "x_train_noisy *= scale # scale\n",
        "x_train_noisy += offset * scale; # add 50 mV offset\n",
        "\n",
        "# Values in [0,1]\n",
        "x_original = np.clip(x_original, 0, 1);\n",
        "x_train_noisy = np.clip(x_train_noisy, 0, 1);\n",
        "\n",
        "# To match the input shape for Conv1D with 1 channel\n",
        "x_original = np.reshape(x_original, (len(x_original), npoints, 1))\n",
        "x_train_noisy = np.reshape(x_train_noisy, (len(x_train_noisy), npoints, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0IXI_u4CKCN",
        "colab_type": "text"
      },
      "source": [
        "## Build model with functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yusCHYE3CNTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(npoints,1))\n",
        "x = Conv1D(64, 5, padding='same', activation=params2['conv_activation'])(input_img)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(32, 5, padding='same', activation=params2['conv_activation'])(x)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(32, 5, padding='same', activation=params2['conv_activation'])(x)\n",
        "encoded = MaxPooling1D(2, padding='same')(x)\n",
        "\n",
        "x = Conv1D(32, 5, padding='same', activation=params2['conv_activation'])(encoded)\n",
        "x = UpSampling1D(2)(x)\n",
        "x = Conv1D(32, 5, padding='same', activation=params2['conv_activation'])(x)\n",
        "x = UpSampling1D(2)(x)\n",
        "x = Conv1D(64, 5, padding='same', activation=params2['conv_activation'])(x)\n",
        "x = UpSampling1D(2)(x)\n",
        "decoded = Conv1D(1, 5, padding='same', activation=params2['output_activation'])(x)\n",
        "\n",
        "autoencoder = Model(inputs=input_img, outputs=decoded)\n",
        "\n",
        "autoencoder.compile(optimizer=params['optimizer'], loss=params['loss']) \n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvNS_i04KgZC",
        "colab_type": "text"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-o1mGrzJR6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=[]\n",
        "if not load_weights:\n",
        "\n",
        "    # Callback for model checkpoints\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath = filename + \"-{epoch:02d}.h5\",\n",
        "        save_best_only=True)\n",
        "    \n",
        "    # 'labels' are the pictures themselves\n",
        "    hist = autoencoder.fit(x_train_noisy, x_original,\n",
        "                           epochs=params['epochs'],\n",
        "                           batch_size=params['batch_size'],\n",
        "                           shuffle=True,\n",
        "                           validation_split=0.1,\n",
        "                           callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "    # Save history\n",
        "    with open(filename + '_hist.json', 'w') as f:\n",
        "        json.dump(hist.history, f)\n",
        "    history = hist.history\n",
        "        \n",
        "    # Save the weights\n",
        "    autoencoder.save_weights(filename + '_weights.h5')\n",
        "else:\n",
        "    # Load weights\n",
        "    autoencoder.load_weights(f'{filename}_weights.h5')\n",
        "\n",
        "    # Load history\n",
        "    with open(f'{filename}_hist.json', 'r') as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "    autoencoder.save(filename + '.h5', include_optimizer=False)\n",
        "        \n",
        "# Plot training history \n",
        "plt.plot(history['loss'], linewidth=3, label='train')\n",
        "plt.plot(history['val_loss'], linewidth=3, label='valid')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(1e-2, 0.1)\n",
        "plt.ylim(1e-5, 1e-3) #mse\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur-JWTe4WI0y",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fYGvPDyWLQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = x_original[-11:]\n",
        "x_test_noisy = x_train_noisy[-11:]\n",
        "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
        "\n",
        "# revert scale and offset\n",
        "x_test -= scale * offset\n",
        "x_test /= scale\n",
        "x_test_noisy -= scale * offset\n",
        "x_test_noisy /= scale\n",
        "decoded_imgs -= scale * offset\n",
        "decoded_imgs /= scale\n",
        "\n",
        "\n",
        "# How many waveforms to be displayed\n",
        "n = 1\n",
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(n):\n",
        "    plt.plot(x_test[i], label=\"original\")\n",
        "    plt.plot(x_test_noisy[i], label=\"noisy\")\n",
        "    plt.plot(decoded_imgs[i], label=\"decoded\")\n",
        "    plt.legend()\n",
        "\n",
        "# Send this plot to comet\n",
        "experiment.log_figure(figure=plt)\n",
        "\n",
        "if plot_data:\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}